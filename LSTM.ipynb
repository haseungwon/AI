{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "    \n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor    \n",
    "\n",
    "torch.manual_seed(125)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (1.0,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST_DATASET/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1b270c2cca41fb877d9d03646ef72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_DATASET/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST_DATASET/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST_DATASET/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283241e0eb67450fa7ab7bc040f1c4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_DATASET/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST_DATASET/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST_DATASET/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb55ca9d1b5427d83b4660c13833fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_DATASET/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST_DATASET/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST_DATASET/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df926c57cbc477fa55e9b87eb32873b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_DATASET/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST_DATASET/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "download_root = './data/MNIST_DATASET/'\n",
    "\n",
    "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=False)\n",
    "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=False)\n",
    "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "valid_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 6000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs =inputs.view(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = inputs[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 28])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,bias=True):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        nn.Linear()\n",
    "        self.x2h = nn.Linear(input_size, 4 *hidden_size, bias=bias)\n",
    "        self.h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std,std)\n",
    "    \n",
    "    def forward(self,x,hidden): # (64,28)의 sequence 하나를 입력받는다\n",
    "        hx, cx = hidden\n",
    "        x = x.view(-1,x.size(1)) # (64,28)로 이쁘게 핀다\n",
    "\n",
    "        gates = self.x2h(x) + self.h2h(hx) #(64,4 * 128)\n",
    "        gates = gates.squeeze()\n",
    "        ingate, forgetgate,cellgate,outgate = gates.chunk(4,1) #(64,28)\n",
    "\n",
    "        ingate = F.sigmoid(ingate)\n",
    "        forgetgate = F.sigmoid(forgetgate)\n",
    "        cellgate = F.sigmoid(cellgate)\n",
    "        outgate = F.sigmoid(outgate)\n",
    "\n",
    "        cy = torch.mul(cx, forgetgate) + torch.mul(ingate,cellgate)\n",
    "        hy = torch.mul(outgate, F.tanh(cy))\n",
    "        return (hy,cy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST는 손으로 쓴 숫자 이미지 데이터입니다. 하나의 이미지는 가로 28개, 세로 28개, 총 784개의 값으로 이루어져 있습니다.\n",
    "\n",
    "Many-to-One model는 여러 시퀀스를 넣었을 때 나오는 최종 결과물만을 이용하는 모델입니다. 이를 이용하여 784개의 input으로 1개의 output값(A) 을 도출합니다. 이 A를 하나의 층에 통과시켜 10개의 숫자 label중 하나를 할당합니다.\n",
    "\n",
    "784개의 입력값을 사이즈가 28인 벡터가 28번 이어지는 시퀀스(time step)로 보고, input의 크기를 28, 시퀀스 길이를 28로 각각 설정합니다. 28개의 input은 C라고 표현되어 있는 LSTM 셀로 순차적으로 들어가게 됩니다.\n",
    "\n",
    "output의 크기는 셀의 크기와 같으며, 64로 설정하였습니다. 셀크기가 너무 작으면 많은 정보를 담지 못하기 때문에 적당히 큰 값으로 설정합니다. 전체 output은 64개의 값을 가지고 있는 벡터 28개의 집합이 되고, 마지막 벡터만 사용합니다.\n",
    "\n",
    "1층의 fully connected layer를 이용하여 64차원 벡터를 10차원으로 줄이고 softmax를 이용하여 0부터 9까지 중 하나의 값을 예측합니다.\n",
    "\n",
    "https://pozalabs.github.io/lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,layer_dim,output_dim, bias=True):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = LSTMCell(input_dim,hidden_dim,layer_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self,x): # x: torch.Size([64, 28, 28]) (batch,seq_dim,input_dim)\n",
    "        # \n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda()) # (1,64,128)\n",
    "        c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda()) # (1,64,128)\n",
    "\n",
    "        outs = []\n",
    "        cn = c0[0,:,:]\n",
    "        hn = h0[0,:,:]\n",
    "\n",
    "        for seq in range(x.size(1)): # range(28)\n",
    "            hn,cn = self.lstm(x[:,seq,:],(hn,cn)) # (64,1,28)로 sequence를 하나씩 전달\n",
    "            outs.append(hn)\n",
    "        \n",
    "        out = outs[-1].squeeze()\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 128\n",
    "layer_dim = 1  \n",
    "output_dim = 10\n",
    " \n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1 \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ha/anaconda3/envs/self/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/ha/anaconda3/envs/self/lib/python3.10/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 2.318148374557495. Accuracy: 9.579999923706055\n",
      "Iteration: 1000. Loss: 2.313196897506714. Accuracy: 10.279999732971191\n",
      "Iteration: 1500. Loss: 2.301957130432129. Accuracy: 10.09000015258789\n",
      "Iteration: 2000. Loss: 2.3158926963806152. Accuracy: 14.430000305175781\n",
      "Iteration: 2500. Loss: 2.2820587158203125. Accuracy: 15.970000267028809\n",
      "Iteration: 3000. Loss: 2.2391583919525146. Accuracy: 20.40999984741211\n",
      "Iteration: 3500. Loss: 2.081110954284668. Accuracy: 23.860000610351562\n",
      "Iteration: 4000. Loss: 2.08986234664917. Accuracy: 32.27000045776367\n",
      "Iteration: 4500. Loss: 1.2805507183074951. Accuracy: 51.400001525878906\n",
      "Iteration: 5000. Loss: 1.153741717338562. Accuracy: 65.5199966430664\n",
      "Iteration: 5500. Loss: 0.8354787230491638. Accuracy: 71.55999755859375\n",
      "Iteration: 6000. Loss: 0.92106032371521. Accuracy: 78.66000366210938\n",
      "Iteration: 6500. Loss: 0.4569924771785736. Accuracy: 84.0\n",
      "Iteration: 7000. Loss: 0.5676109790802002. Accuracy: 85.08000183105469\n",
      "Iteration: 7500. Loss: 0.21874430775642395. Accuracy: 88.33999633789062\n",
      "Iteration: 8000. Loss: 0.21410459280014038. Accuracy: 90.56999969482422\n",
      "Iteration: 8500. Loss: 0.44085004925727844. Accuracy: 88.81999969482422\n",
      "Iteration: 9000. Loss: 0.15915367007255554. Accuracy: 92.54000091552734\n"
     ]
    }
   ],
   "source": [
    "seq_dim = 28\n",
    "loss_list = []\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1,seq_dim,input_dim).cuda()) #torch.Size([64, 1, 28, 28]) -> torch.Size([64, 28, 28])으로 변경\n",
    "        labels = Variable(labels.cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.cuda()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "        iter +=1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for images, labels in valid_loader:\n",
    "                images = Variable(images.view(-1,seq_dim,input_dim).cuda())\n",
    "                outputs = model(images)\n",
    "                _,predicted = torch.max(outputs.data,1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    corrects, total, total_loss = 0,0,0\n",
    "    model.eval()\n",
    "\n",
    "    for images, labels in val_iter:\n",
    "        images = Variable(images.view(-1,seq_dim,input_dim).cuda())\n",
    "        \n",
    "        labels = Variable(labels.cuda())\n",
    "        \n",
    "        logit = model(images).to(device)\n",
    "        loss = F.cross_entropy(logit,labels,reduction='sum')\n",
    "        \n",
    "        _, pred = torch.max(logit.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        corrects += (pred == labels).sum()\n",
    "    \n",
    "    avg_loss = total_loss / len(val_iter)\n",
    "    avg_accuracy = corrects / total\n",
    "    return avg_loss, avg_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 16.11 | Test Accuracy:  0.92\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader)\n",
    "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca1393ca72916ec0733d2ed243a44f77efd842c1212a40384120ea0a56403e11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
