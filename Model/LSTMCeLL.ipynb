{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "    \n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor    \n",
    "\n",
    "torch.manual_seed(125)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (1.0,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "download_root = '../data/MNIST_DATASET/'\n",
    "\n",
    "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=False)\n",
    "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=False)\n",
    "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "valid_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 6000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs =inputs.view(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = inputs[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,bias=True):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.x2h = nn.Linear(input_size, 4 *hidden_size, bias=bias)\n",
    "        self.h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std,std)\n",
    "    \n",
    "    def forward(self,x,hidden): # (64,28)의 sequence 하나를 입력받는다\n",
    "        hx, cx = hidden\n",
    "        x = x.view(-1,x.size(1)) # (64,28)로 이쁘게 핀다\n",
    "\n",
    "        gates = self.x2h(x) + self.h2h(hx) #(64,4 * 128)\n",
    "        gates = gates.squeeze()\n",
    "        ingate, forgetgate,cellgate,outgate = gates.chunk(4,1) #(64,28)\n",
    "\n",
    "        ingate = F.sigmoid(ingate)\n",
    "        forgetgate = F.sigmoid(forgetgate)\n",
    "        cellgate = F.sigmoid(cellgate)\n",
    "        outgate = F.sigmoid(outgate)\n",
    "\n",
    "        cy = torch.mul(cx, forgetgate) + torch.mul(ingate,cellgate)\n",
    "        hy = torch.mul(outgate, F.tanh(cy))\n",
    "        return (hy,cy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST는 손으로 쓴 숫자 이미지 데이터입니다. 하나의 이미지는 가로 28개, 세로 28개, 총 784개의 값으로 이루어져 있습니다.\n",
    "\n",
    "Many-to-One model는 여러 시퀀스를 넣었을 때 나오는 최종 결과물만을 이용하는 모델입니다. 이를 이용하여 784개의 input으로 1개의 output값(A) 을 도출합니다. 이 A를 하나의 층에 통과시켜 10개의 숫자 label중 하나를 할당합니다.\n",
    "\n",
    "784개의 입력값을 사이즈가 28인 벡터가 28번 이어지는 시퀀스(time step)로 보고, input의 크기를 28, 시퀀스 길이를 28로 각각 설정합니다. 28개의 input은 C라고 표현되어 있는 LSTM 셀로 순차적으로 들어가게 됩니다.\n",
    "\n",
    "output의 크기는 셀의 크기와 같으며, 64로 설정하였습니다. 셀크기가 너무 작으면 많은 정보를 담지 못하기 때문에 적당히 큰 값으로 설정합니다. 전체 output은 64개의 값을 가지고 있는 벡터 28개의 집합이 되고, 마지막 벡터만 사용합니다.\n",
    "\n",
    "1층의 fully connected layer를 이용하여 64차원 벡터를 10차원으로 줄이고 softmax를 이용하여 0부터 9까지 중 하나의 값을 예측합니다.\n",
    "\n",
    "https://pozalabs.github.io/lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,layer_dim,output_dim, bias=True):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = LSTMCell(input_dim,hidden_dim,layer_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self,x): # x: torch.Size([64, 28, 28]) (batch,seq_dim,input_dim)\n",
    "        # \n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda()) # (1,64,128)\n",
    "        c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda()) # (1,64,128)\n",
    "\n",
    "        outs = []\n",
    "        cn = c0[0,:,:]\n",
    "        hn = h0[0,:,:]\n",
    "\n",
    "        for seq in range(x.size(1)): # range(28)\n",
    "            hn,cn = self.lstm(x[:,seq,:],(hn,cn)) # (64,1,28)로 sequence를 하나씩 전달\n",
    "            outs.append(hn)\n",
    "        \n",
    "        out = outs[-1].squeeze()\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 128\n",
    "layer_dim = 1  \n",
    "output_dim = 10\n",
    " \n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1 \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ha/anaconda3/envs/self/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/ha/anaconda3/envs/self/lib/python3.10/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 2.301367998123169. Accuracy: 10.09000015258789\n",
      "Iteration: 1000. Loss: 2.300041675567627. Accuracy: 11.350000381469727\n",
      "Iteration: 1500. Loss: 2.3201262950897217. Accuracy: 10.229999542236328\n",
      "Iteration: 2000. Loss: 2.2970528602600098. Accuracy: 10.279999732971191\n",
      "Iteration: 2500. Loss: 2.2516183853149414. Accuracy: 11.760000228881836\n",
      "Iteration: 3000. Loss: 2.2531661987304688. Accuracy: 16.610000610351562\n",
      "Iteration: 3500. Loss: 2.166072368621826. Accuracy: 20.280000686645508\n",
      "Iteration: 4000. Loss: 1.7078289985656738. Accuracy: 36.529998779296875\n",
      "Iteration: 4500. Loss: 1.221008539199829. Accuracy: 59.56999969482422\n",
      "Iteration: 5000. Loss: 0.8756988644599915. Accuracy: 72.26000213623047\n",
      "Iteration: 5500. Loss: 0.687919557094574. Accuracy: 74.58999633789062\n",
      "Iteration: 6000. Loss: 0.6276847720146179. Accuracy: 75.47000122070312\n",
      "Iteration: 6500. Loss: 0.49487772583961487. Accuracy: 84.80000305175781\n",
      "Iteration: 7000. Loss: 0.24680334329605103. Accuracy: 86.86000061035156\n",
      "Iteration: 7500. Loss: 0.29509878158569336. Accuracy: 88.9800033569336\n",
      "Iteration: 8000. Loss: 0.2328171581029892. Accuracy: 90.4800033569336\n",
      "Iteration: 8500. Loss: 0.36641010642051697. Accuracy: 90.93000030517578\n",
      "Iteration: 9000. Loss: 0.17560601234436035. Accuracy: 91.69000244140625\n"
     ]
    }
   ],
   "source": [
    "seq_dim = 28\n",
    "loss_list = []\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1,seq_dim,input_dim).cuda()) #torch.Size([64, 1, 28, 28]) -> torch.Size([64, 28, 28])으로 변경\n",
    "        labels = Variable(labels.cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.cuda()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "        iter +=1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for images, labels in valid_loader:\n",
    "                images = Variable(images.view(-1,seq_dim,input_dim).cuda())\n",
    "                outputs = model(images)\n",
    "                _,predicted = torch.max(outputs.data,1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    corrects, total, total_loss = 0,0,0\n",
    "    model.eval()\n",
    "\n",
    "    for images, labels in val_iter:\n",
    "        images = Variable(images.view(-1,seq_dim,input_dim).cuda())\n",
    "        \n",
    "        labels = Variable(labels.cuda())\n",
    "        \n",
    "        logit = model(images).to(device)\n",
    "        loss = F.cross_entropy(logit,labels,reduction='sum')\n",
    "        \n",
    "        _, pred = torch.max(logit.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        corrects += (pred == labels).sum()\n",
    "    \n",
    "    avg_loss = total_loss / len(val_iter)\n",
    "    avg_accuracy = corrects / total\n",
    "    return avg_loss, avg_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 21.03 | Test Accuracy:  0.90\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader)\n",
    "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca1393ca72916ec0733d2ed243a44f77efd842c1212a40384120ea0a56403e11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
