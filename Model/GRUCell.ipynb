{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "    \n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor    \n",
    "\n",
    "torch.manual_seed(125)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (1.0,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "download_root = '../data/MNIST_DATASET/'\n",
    "\n",
    "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=False)\n",
    "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=False)\n",
    "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "valid_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 6000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,bias=True):\n",
    "        super().__init__()\n",
    "        self.input_size= input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.x2h = nn.Linear(input_size,3 * hidden_size, bias=bias)\n",
    "        self.h2h = nn.Linear(hidden_size,3*hidden_size,bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std,std)\n",
    "    \n",
    "    def forward(self,x,hidden):\n",
    "        x = x.view(-1,x.size(1))\n",
    "\n",
    "        gate_x = self.x2h(x)\n",
    "        gate_h = self.h2h(hidden)\n",
    "\n",
    "        # Returns a tensor with all the dimensions of input of size 1 removed.\n",
    "        gate_x = gate_x.squeeze()\n",
    "        gate_h = gate_h.squeeze()\n",
    "\n",
    "        i_r,i_i,i_n = gate_x.chunk(3,1)\n",
    "        h_r,h_i,h_n = gate_h.chunk(3,1)\n",
    "\n",
    "        resetgate = F.sigmoid(i_r+h_r)\n",
    "        inputgate = F.sigmoid(i_i+h_i)\n",
    "        newgate = F.tanh(i_n + (resetgate*h_n))\n",
    "\n",
    "        hy = newgate + inputgate *(hidden - newgate)\n",
    "        return hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,layer_dim,output_dim,bias=True):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        self.gru_cell = GRUCell(input_dim,hidden_dim,layer_dim)\n",
    "        self.fc = nn.Linear(hidden_dim,output_dim)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h0 = Variable(torch.zeros(self.layer_dim,x.size(0),self.hidden_dim).cuda())\n",
    "        outs = []\n",
    "        hn = h0[0,:,:]\n",
    "\n",
    "        for seq in range(x.size(1)):\n",
    "            hn = self.gru_cell(x[:,seq,:],hn)\n",
    "            outs.append(hn)\n",
    "        out = outs[-1].squeeze()\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 128\n",
    "layer_dim = 1  \n",
    "output_dim = 10\n",
    " \n",
    "model = GRUModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    " \n",
    "\n",
    "model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1 \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ha/anaconda3/envs/self/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/ha/anaconda3/envs/self/lib/python3.10/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.6616928577423096. Accuracy: 43.59000015258789\n",
      "Iteration: 1000. Loss: 0.8945668339729309. Accuracy: 76.19999694824219\n",
      "Iteration: 1500. Loss: 0.29147759079933167. Accuracy: 89.7300033569336\n",
      "Iteration: 2000. Loss: 0.23627926409244537. Accuracy: 93.51000213623047\n",
      "Iteration: 2500. Loss: 0.032887231558561325. Accuracy: 95.05000305175781\n",
      "Iteration: 3000. Loss: 0.030374981462955475. Accuracy: 95.81999969482422\n",
      "Iteration: 3500. Loss: 0.1621057391166687. Accuracy: 96.33999633789062\n",
      "Iteration: 4000. Loss: 0.19308774173259735. Accuracy: 96.19000244140625\n",
      "Iteration: 4500. Loss: 0.05172009393572807. Accuracy: 97.0\n",
      "Iteration: 5000. Loss: 0.1390017420053482. Accuracy: 97.26000213623047\n",
      "Iteration: 5500. Loss: 0.08090292662382126. Accuracy: 97.62000274658203\n",
      "Iteration: 6000. Loss: 0.10488361120223999. Accuracy: 97.69000244140625\n",
      "Iteration: 6500. Loss: 0.0798402726650238. Accuracy: 97.80000305175781\n",
      "Iteration: 7000. Loss: 0.10250391066074371. Accuracy: 97.55999755859375\n",
      "Iteration: 7500. Loss: 0.06477978080511093. Accuracy: 97.86000061035156\n",
      "Iteration: 8000. Loss: 0.10547614097595215. Accuracy: 97.80000305175781\n",
      "Iteration: 8500. Loss: 0.04281153902411461. Accuracy: 98.0199966430664\n",
      "Iteration: 9000. Loss: 0.04198871925473213. Accuracy: 98.22000122070312\n"
     ]
    }
   ],
   "source": [
    "seq_dim = 28 \n",
    "loss_list = []\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):         \n",
    "        \n",
    "        images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.cuda()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "        iter += 1\n",
    "         \n",
    "        if iter % 500 == 0:         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in valid_loader:\n",
    "\n",
    "                images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "                \n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "\n",
    "             \n",
    "            accuracy = 100 * correct / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):    \n",
    "    corrects, total, total_loss = 0, 0, 0\n",
    "    model.eval()\n",
    "    for images, labels in val_iter:\n",
    "\n",
    "        images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "\n",
    "        logit = model(images).to(device)\n",
    "        loss = F.cross_entropy(logit, labels, reduction = \"sum\")\n",
    "        _, predicted = torch.max(logit.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total_loss += loss.item()\n",
    "        corrects += (predicted == labels).sum()\n",
    "\n",
    "    avg_loss = total_loss / len(val_iter.dataset)\n",
    "    avg_accuracy = corrects / total\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument target in method wrapper_nll_loss_forward)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m evaluate(model,test_loader)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest Loss: \u001b[39m\u001b[39m%5.2f\u001b[39;00m\u001b[39m | Test Accuracy: \u001b[39m\u001b[39m%5.2f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (test_loss, test_acc))\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, val_iter)\u001b[0m\n\u001b[1;32m      6\u001b[0m images \u001b[39m=\u001b[39m Variable(images\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, seq_dim, input_dim)\u001b[39m.\u001b[39mcuda())\n\u001b[1;32m      8\u001b[0m logit \u001b[39m=\u001b[39m model(images)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mcross_entropy(logit, labels, reduction \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(logit\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/self/lib/python3.10/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument target in method wrapper_nll_loss_forward)"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model,test_loader)\n",
    "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca1393ca72916ec0733d2ed243a44f77efd842c1212a40384120ea0a56403e11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
